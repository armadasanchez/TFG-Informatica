{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import math\n",
    "import csv\n",
    "import os\n",
    "import statistics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'E:/Documentos/PCEO/5/Informatica/TFG/datos/anonamyze_all_data_collection_v2.csv'\n",
    "dataEvents = pd.read_csv(path, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "{'1. One Box': {'GMD.4': -1.879, 'CO.5': -1.879, 'CO.6': -1.879},\n '2. Separated Boxes': {'GMD.4': -1.765, 'CO.5': -1.765, 'CO.6': -1.765},\n '3. Rotate a Pyramid': {'GMD.4': -1.654, 'CO.5': -1.653, 'CO.6': -1.654},\n '4. Match Silhouettes': {'GMD.4': -1.486, 'CO.5': -1.486, 'CO.6': -1.486},\n 'Sugar Cones': {'GMD.4': -1.031, 'CO.5': -1.022, 'CO.6': -1.031},\n '8. Combine 2 Ramps': {'GMD.4': -1.34, 'CO.5': -1.34, 'CO.6': -1.34},\n '9. Scaling Round Objects': {'GMD.4': -1.332, 'CO.5': -1.331, 'CO.6': -1.331},\n 'Square Cross-Sections': {'GMD.4': -0.937, 'CO.5': -0.937, 'CO.6': -0.937},\n 'Bird Fez': {'MG.1': -1.166, 'GMD.4': -0.51, 'CO.5': -0.511, 'CO.6': -0.51},\n 'Pi Henge': {'MG.1': -1.619, 'GMD.4': -0.676, 'CO.5': -0.675, 'CO.6': -0.676},\n '45-Degree Rotations': {'GMD.4': -0.983, 'CO.5': -1.471, 'CO.6': -0.982},\n 'Pyramids are Strange': {'GMD.4': -0.652, 'CO.5': -0.646, 'CO.6': -0.652},\n 'Boxes Obscure Spheres': {'GMD.4': -0.053, 'CO.5': -0.125, 'CO.6': -0.05},\n 'Object Limits': {'GMD.4': -0.363, 'CO.5': -0.352, 'CO.6': -0.361},\n 'Tetromino': {'GMD.4': -0.244, 'CO.5': -0.237, 'CO.6': -0.244},\n 'Angled Silhouette': {'GMD.4': -0.605, 'CO.5': -0.598, 'CO.6': -0.604},\n 'Stranger Shapes': {'GMD.4': -0.308, 'CO.5': -0.245, 'CO.6': -0.25},\n 'Tall and Small': {'GMD.4': -0.202, 'CO.5': -0.196, 'CO.6': -0.319},\n '5. Removing Objects': {'GMD.4': -1.42, 'CO.5': -1.42, 'CO.6': -1.42},\n '6. Stretch a Ramp': {'GMD.4': -1.485, 'CO.5': -1.485, 'CO.6': -1.485},\n '7. Max 2 Boxes': {'GMD.4': -1.301, 'CO.5': -1.301, 'CO.6': -1.301},\n 'Ramp Up and Can It': {'GMD.4': -0.34, 'CO.5': -0.184, 'CO.6': -0.192},\n 'More Than Meets Your Eye': {'GMD.4': -0.736, 'CO.5': -0.731, 'CO.6': -0.735},\n 'Bear Market': {'GMD.4': 0.952, 'CO.5': 0.96, 'CO.6': 0.957},\n 'Not Bird': {'GMD.4': 0.136, 'CO.5': 0.124, 'CO.6': 0.121},\n 'Warm Up': {'GMD.4': -1.325, 'CO.5': -1.32, 'CO.6': -1.324},\n 'Unnecessary': {'GMD.4': -0.236, 'CO.5': -0.234, 'CO.6': -0.24},\n 'Zzz': {'GMD.4': -0.167, 'CO.5': -0.161, 'CO.6': -0.165},\n 'Bull Market': {'MG.1': -0.253,\n  'GMD.4': -0.013,\n  'CO.5': -0.011,\n  'CO.6': -0.011},\n 'Few Clues': {'GMD.4': -0.109, 'CO.5': -0.046, 'CO.6': -0.049},\n 'Orange Dance': {'GMD.4': 0.359, 'CO.5': 0.358, 'CO.6': 0.355}}"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difficulty_puzzles = pd.read_csv('E:/Documentos/PCEO/5/Informatica/TFG/scripts/TFG-Informatica/Outputs/elo-puzzle-Output.csv', sep=\";\")\n",
    "\n",
    "difficulty_puzzles_dict = {}\n",
    "for index, row in difficulty_puzzles.iterrows():\n",
    "    task_id = row['task_id']\n",
    "    kc = row['kc']\n",
    "    difficulty = row['difficulty']\n",
    "    if task_id not in difficulty_puzzles_dict:\n",
    "        difficulty_puzzles_dict[task_id] = {}\n",
    "    difficulty_puzzles_dict[task_id][kc] = difficulty\n",
    "\n",
    "difficulty_puzzles_dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = 'user'\n",
    "timestamp = 'initial timestamp'\n",
    "student_column_number = 1\n",
    "group_column_number = 0\n",
    "completed = 'n_completed'\n",
    "puzzle_name = 'task_id'\n",
    "puzzle_column_number = 2\n",
    "kc_column = 'kc'\n",
    "kc_column_number = 4\n",
    "\n",
    "kcs = ['GMD.4', 'CO.5', 'CO.6','MG.1']\n",
    "mg1Puzzles = ['Bird Fez', 'Pi Henge', 'Bull Market']\n",
    "gmd4Puzzles = ['Angled Silhouettes', 'Not Bird', 'Stranger Shapes', 'Ramp Up and Can It', 'Few Clues']\n",
    "co5Puzzles = ['45-Degree Rotations', 'Boxes Obscure Spheres', 'More Than Meets the Eye']\n",
    "co6Puzzles = ['Tall and Small', 'Not Bird', 'Ramp Up and Can It', 'Stretch a Ramp', 'Max 2 Boxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeMappingDifficulty = ['Sandbox~SAND', '1. One Box~Tutorial', '2. Separated Boxes~Tutorial', '3. Rotate a Pyramid~Tutorial', '4. Match Silhouettes~Tutorial', '5. Removing Objects~Tutorial', '6. Stretch a Ramp~Tutorial', '7. Max 2 Boxes~Tutorial', '8. Combine 2 Ramps~Tutorial', '9. Scaling Round Objects~Tutorial', \n",
    "               'Square Cross-Sections~Easy Puzzles', 'Bird Fez~Easy Puzzles', 'Pi Henge~Easy Puzzles', '45-Degree Rotations~Easy Puzzles',  'Pyramids are Strange~Easy Puzzles', 'Boxes Obscure Spheres~Easy Puzzles', 'Object Limits~Easy Puzzles', 'Not Bird~Easy Puzzles', 'Angled Silhouette~Easy Puzzles',\n",
    "               'Warm Up~Hard Puzzles','Tetromino~Hard Puzzles', 'Stranger Shapes~Hard Puzzles', 'Sugar Cones~Hard Puzzles', 'Tall and Small~Hard Puzzles', 'Ramp Up and Can It~Hard Puzzles', 'More Than Meets Your Eye~Hard Puzzles', 'Unnecessary~Hard Puzzles', 'Zzz~Hard Puzzles', 'Bull Market~Hard Puzzles', 'Few Clues~Hard Puzzles', 'Orange Dance~Hard Puzzles', 'Bear Market~Hard Puzzles']\n",
    "\n",
    "tutorialPuzzles = []\n",
    "\n",
    "for puzzle in typeMappingDifficulty:\n",
    "    desc = puzzle.split(\"~\")\n",
    "    if(desc[1] == 'Tutorial'):\n",
    "        tutorialPuzzles.append(desc[0])\n",
    "        \n",
    "advancedPuzzles = []\n",
    "\n",
    "for puzzle in typeMappingDifficulty:\n",
    "    desc = puzzle.split(\"~\")\n",
    "    if(desc[1] == 'Hard Puzzles'):\n",
    "        advancedPuzzles.append(desc[0])\n",
    "        \n",
    "        \n",
    "intermediatePuzzles = []\n",
    "\n",
    "for puzzle in typeMappingDifficulty:\n",
    "    desc = puzzle.split(\"~\")\n",
    "    if(desc[1] == 'Easy Puzzles'):\n",
    "        intermediatePuzzles.append(desc[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping to positions\n",
    "\n",
    "typeMappingKC = {'Sandbox': 'GMD.4~CO.5~CO.6', '1. One Box': 'GMD.4~CO.5~CO.6', '2. Separated Boxes': 'GMD.4~CO.5~CO.6', '3. Rotate a Pyramid': 'GMD.4~CO.5~CO.6', '4. Match Silhouettes': 'GMD.4~CO.5~CO.6', '5. Removing Objects': 'GMD.4~CO.5~CO.6', '6. Stretch a Ramp': 'GMD.4~CO.5~CO.6', '7. Max 2 Boxes': 'GMD.4~CO.5~CO.6', '8. Combine 2 Ramps': 'GMD.4~CO.5~CO.6', '9. Scaling Round Objects': 'GMD.4~CO.5~CO.6','Square Cross-Sections': 'GMD.4~CO.5~CO.6', 'Bird Fez': 'MG.1~GMD.4~CO.5~CO.6' , 'Pi Henge': 'MG.1~GMD.4~CO.5~CO.6', '45-Degree Rotations': 'GMD.4~CO.5~CO.6',  'Pyramids are Strange': 'GMD.4~CO.5~CO.6', 'Boxes Obscure Spheres': 'GMD.4~CO.5~CO.6', 'Object Limits': 'GMD.4~CO.5~CO.6', 'Tetromino': 'GMD.4~CO.5~CO.6', 'Angled Silhouette': 'GMD.4~CO.5~CO.6','Warm Up':'GMD.4~CO.5~CO.6','Sugar Cones': 'GMD.4~CO.5~CO.6', 'Stranger Shapes': 'GMD.4~CO.5~CO.6', 'Tall and Small': 'GMD.4~CO.5~CO.6', 'Ramp Up and Can It': 'GMD.4~CO.5~CO.6', 'More Than Meets Your Eye': 'GMD.4~CO.5~CO.6', 'Not Bird': 'GMD.4~CO.5~CO.6', 'Unnecessary': 'GMD.4~CO.5~CO.6', 'Zzz': 'GMD.4~CO.5~CO.6', 'Bull Market': 'MG.1~GMD.4~CO.5~CO.6', 'Few Clues': 'GMD.4~CO.5~CO.6', 'Orange Dance': 'GMD.4~CO.5~CO.6', 'Bear Market': 'GMD.4~CO.5~CO.6'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def adaptedData(dataEvents, group = 'all'):\n",
    "    dataEvents['time'] = pd.to_datetime(dataEvents['time'])\n",
    "    dataEvents = dataEvents.sort_values('time')\n",
    "    \n",
    "    #iterates in the groups and users of the data\n",
    "    dataEvents['group'] = [json.loads(x)['group'] if 'group' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['user'] = [json.loads(x)['user'] if 'user' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    dataEvents['task_id'] = [json.loads(x)['task_id'] if 'task_id' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "    \n",
    "    # removing those rows where we dont have a group and a user that is not guest\n",
    "    dataEvents = dataEvents[((dataEvents['group'] != '') & (dataEvents['user'] != '') & (dataEvents['user'] != 'guest'))]\n",
    "    dataEvents['group_user_id'] = dataEvents['group'] + '~' + dataEvents['user']\n",
    "    dataEvents['group_user_task_id'] = dataEvents['group'] + '~' + dataEvents['user']+'~'+dataEvents['task_id']\n",
    "\n",
    "         \n",
    "    # filtering to only take the group passed as argument\n",
    "          \n",
    "    activity_by_user = dataEvents.groupby(['group_user_id']).agg({'id':'count',\n",
    "                                             'type':'nunique'}).reset_index().rename(columns={'id':'events',\n",
    "                                                                                              'type':'different_events'}) \n",
    "    \n",
    "    \n",
    "                                                                                              \n",
    "    #initialize the metrics          \n",
    "    activity_by_user['active_time'] = np.nan\n",
    "    activity_by_user['n_completed'] = 0\n",
    "    activity_by_user['kc'] = ''\n",
    "    #initialize the data structures\n",
    "    puzzleEvents = dict()\n",
    "    timePuzzle = dict()\n",
    "    puzzCom= dict()\n",
    "    puzzDestr = dict()\n",
    "    initialTime = dict()\n",
    "    \n",
    "    n_attempts = dict()\n",
    "    attData = dict()\n",
    "    \n",
    "    userPuzzleInit = dict()\n",
    "    n_attemptsAux = dict()\n",
    "    \n",
    "    userTrain = set()\n",
    "    userTest = set()\n",
    "    userTotal = set()\n",
    "    \n",
    "    \n",
    "    for user in dataEvents['group_user_id'].unique():\n",
    "        \n",
    "        # Computing active time\n",
    "        previousEvent = None\n",
    "        theresHoldActivity = 60 # np.percentile(allDifferences, 98) is 10 seconds\n",
    "        activeTime = []\n",
    "        \n",
    "        user_events = dataEvents[dataEvents['group_user_id'] == user]\n",
    "        user_puzzle_key = None\n",
    "\n",
    "        for enum, event in user_events.iterrows():\n",
    "            \n",
    "            if(event['type'] in ['ws-start_level', 'ws-puzzle_started']):\n",
    "                \n",
    "                if(json.loads(event['data'])['task_id'] == 'Sandbox'): continue\n",
    "                \n",
    "                partialKey = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id']\n",
    "                \n",
    "                if(event['user'] not in userTotal):\n",
    "                    userTotal.add(event['user'])\n",
    "\n",
    "                \n",
    "                if(partialKey not in n_attemptsAux.keys()): \n",
    "                    n_attemptsAux[partialKey] = 0\n",
    "                    puzzCom[partialKey] = 0\n",
    "                    \n",
    "                    \n",
    "                if(partialKey not in userPuzzleInit.keys()): \n",
    "                    \n",
    "                    n_attempts[partialKey] = 1\n",
    "                    user_puzzle_key = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id'] + '~' + str(n_attempts[partialKey])\n",
    "                    userPuzzleInit[partialKey] = 1\n",
    "                    \n",
    "                else: \n",
    "                    \n",
    "                    n_attempts[partialKey] += 1\n",
    "                    user_puzzle_key = event['group'] + '~' + event['user'] + '~' + json.loads(event['data'])['task_id'] + '~' + str(n_attempts[partialKey])\n",
    "                    \n",
    "            \n",
    "                # initialize if the id is new                                                                              \n",
    "                if(user_puzzle_key not in puzzleEvents.keys()):\n",
    "                    attData[user_puzzle_key] = {'att': 0, 'completed': 0,'dataCompleted': 0, 'accept': 0, 'timestamp': event['time'], 'repeat':0}\n",
    "                    puzzleEvents[user_puzzle_key]= 1\n",
    "                    timePuzzle[user_puzzle_key] = 0\n",
    "                    puzzDestr[user_puzzle_key] = ''\n",
    "                    initialTime[user_puzzle_key] = 0\n",
    "                                        \n",
    "                    \n",
    "                if(event['type'] in ['ws-puzzle_started']): \n",
    "                    attData[user_puzzle_key]['timestamp'] = event['time']\n",
    "                    \n",
    "            # the event is not final event\n",
    "            if(event['type'] not in ['ws-exit_to_menu', 'ws-puzzle_complete', 'ws-create_user', 'ws-login_user']): \n",
    "                if(user_puzzle_key in puzzleEvents.keys()):\n",
    "                    puzzleEvents[user_puzzle_key] += 1\n",
    "                    splitDes = user_puzzle_key.split(\"~\")\n",
    "                    puzzDestr[user_puzzle_key] = typeMappingKC[splitDes[2]]                                                                          \n",
    "                    if(event['type'] == 'ws-check_solution'):\n",
    "                        attData[user_puzzle_key]['accept'] = 1\n",
    "                        \n",
    "                        \n",
    "                       \n",
    "                        \n",
    "            # the puzzle ends        \n",
    "            if(event['type'] in ['ws-exit_to_menu', 'ws-puzzle_complete', 'ws-disconnect']):\n",
    "                \n",
    "                if(user_puzzle_key in puzzleEvents.keys()):\n",
    "                    #the data is consistent\n",
    "                    attData[user_puzzle_key]['dataCompleted'] += 1\n",
    "                    #the data is valid\n",
    "                    if(attData[user_puzzle_key]['accept'] == 1 and attData[user_puzzle_key]['dataCompleted']==1):\n",
    "                        n_attemptsAux[partialKey]+=1\n",
    "                        attData[user_puzzle_key]['att'] = n_attemptsAux[partialKey]\n",
    "                        #attempt after solving\n",
    "                        if(event['type'] in ['ws-puzzle_complete']):\n",
    "                            if(puzzCom[partialKey] !=0 and n_attemptsAux[partialKey] > 1):\n",
    "                                attData[user_puzzle_key]['repeat'] = 1\n",
    "                    \n",
    "                    if(event['type'] in ['ws-puzzle_complete']):\n",
    "                        if(puzzCom[partialKey] ==0):\n",
    "                            attData[user_puzzle_key]['completed'] = 1\n",
    "                            if(attData[user_puzzle_key]['accept'] == 1):\n",
    "                                puzzCom[partialKey] +=1\n",
    "\n",
    "                    \n",
    "    \n",
    "    \n",
    "    # add the data by group_user_task_id            \n",
    "    for i in attData.keys(): \n",
    "        key_split = i.split('~')            \n",
    "            \n",
    "        if(len(userTrain) < round(len(userTotal)*0.7)):\n",
    "            userTrain.add(key_split[1])\n",
    "        else: \n",
    "            if(key_split[1] not in userTrain): userTest.add(key_split[1]) \n",
    "                \n",
    "                \n",
    "        \n",
    "        if(key_split[2] != '' and key_split[2] != 'Sandbox' and key_split[3] != '' and i != '' and key_split[1] != ''):\n",
    "            if(attData[i]['accept'] != 0 and attData[i]['dataCompleted'] != 0 and attData[i]['repeat'] == 0):\n",
    "               \n",
    "                # data output preparation\n",
    "                activity_by_user.at[i, 'group_user_task_att'] = key_split[0] + '~' + key_split[1] + '~' + key_split[2] + '~' + str(attData[i]['att'])\n",
    "                activity_by_user.at[i, 'group'] = key_split[0]\n",
    "                activity_by_user.at[i, 'user'] = key_split[1]\n",
    "                activity_by_user.at[i, 'task_id'] = key_split[2]\n",
    "                activity_by_user.at[i, 'attempt'] = attData[i]['att']\n",
    "                activity_by_user.at[i, 'repeat'] = attData[i]['repeat']\n",
    "                activity_by_user.at[i, 'kc'] = puzzDestr[i]\n",
    "                activity_by_user.at[i, 'n_completed'] = attData[i]['completed']\n",
    "                activity_by_user.at[i, 'initial timestamp'] = attData[i]['timestamp']\n",
    "\n",
    "    \n",
    "    #delete row with NaN\n",
    "    activity_by_user.dropna(subset = ['user'], inplace=True)\n",
    "  \n",
    "    #data output preparation             \n",
    "    activity_by_user = pd.DataFrame(activity_by_user, columns = ['group_user_task_att', 'group','user','task_id','n_completed', 'kc', 'initial timestamp'])\n",
    "\n",
    "\n",
    "    train = activity_by_user[activity_by_user['user'].isin(userTrain)]\n",
    "    test = activity_by_user[activity_by_user['user'].isin(userTest)]\n",
    "    \n",
    "    return activity_by_user, train, test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict users: uDict\n",
    "def usersDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapUsers = {}\n",
    "    mapGroups = {}\n",
    "    cont =0\n",
    "    for row in csv_file.iterrows():\n",
    "        user = row[1]['user']\n",
    "        group = row[1]['group']\n",
    "        if user not in mapUsers.keys():\n",
    "            mapUsers[user]=cont\n",
    "            mapGroups[user] = group\n",
    "            cont = cont+1\n",
    "    return mapUsers, mapGroups  \n",
    "\n",
    "\n",
    "# Dict puzzles: qDict\n",
    "def puzzlesDict(datafile):\n",
    "    csv_file = datafile\n",
    "    mapPuzzles = {}\n",
    "    cont =0\n",
    "    for row in csv_file.iterrows():\n",
    "        question = row[1]['task_id']\n",
    "        if question not in mapPuzzles.keys():\n",
    "            mapPuzzles[question]=cont\n",
    "            cont = cont+1\n",
    "    return mapPuzzles\n",
    "\n",
    "\n",
    "\n",
    "# Dict kcs: kcDict \n",
    "def kcsDict(datafile):\n",
    "    QT = []\n",
    "    csv_file = datafile\n",
    "    mapKc = {}\n",
    "    cont =0\n",
    "    for row in csv_file.iterrows():\n",
    "        tags = row[1]['kc'] \n",
    "        if tags:\n",
    "            tag = tags.split(\"~\")\n",
    "            for topics in tag:\n",
    "                if topics not in mapKc.keys():\n",
    "                    mapKc[topics]=cont\n",
    "                    cont = cont + 1\n",
    "    return mapKc\n",
    "\n",
    "def createKcDict(datafile):\n",
    "    \n",
    "    QTMat = dict()\n",
    "    csv_file = datafile\n",
    "    for row in csv_file.iterrows():\n",
    "        qid = row[1]['task_id']\n",
    "        kcs = row[1]['kc']\n",
    "        if(qid not in QTMat.keys()):\n",
    "            QTMat[qid]=dict()\n",
    "        if kcs:\n",
    "            kc = kcs.split(\"~\")\n",
    "            for k in kc:\n",
    "                QTMat[qid][k] =0\n",
    "\n",
    "\n",
    "    for puzzle in QTMat.keys():\n",
    "        tam = len(QTMat[puzzle])\n",
    "        if tam>0:   \n",
    "            if(puzzle in mg1Puzzles):\n",
    "                QTMat[puzzle]['MG.1'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'MG.1'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)\n",
    "            elif(puzzle in gmd4Puzzles): \n",
    "                QTMat[puzzle]['GMD.4'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'GMD.4'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)\n",
    "            elif(puzzle in co5Puzzles): \n",
    "                QTMat[puzzle]['CO.5'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'CO.5'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)\n",
    "            elif(puzzle in co6Puzzles):  \n",
    "                QTMat[puzzle]['CO.6'] = 0.5\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    if(x != 'CO.6'):\n",
    "                        QTMat[puzzle][x] = 0.5/(tam-1)              \n",
    "            else:\n",
    "                for x in QTMat[puzzle].keys():\n",
    "                    QTMat[puzzle][x] = 1/tam\n",
    "    return QTMat\n",
    "\n",
    "\n",
    "def loadDataset(datafile):\n",
    "    uDict, gDict = usersDict(datafile) \n",
    "    qDict =puzzlesDict(datafile)\n",
    "    kcDict =kcsDict(datafile)\n",
    "    kcsPuzzleDict =  createKcDict(datafile) \n",
    "\n",
    "    return uDict, gDict,qDict,kcDict, kcsPuzzleDict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmseFunction(prob, ans, lenProb):\n",
    "    prob = np.array(prob)\n",
    "    ground = np.array(ans)\n",
    "    error = (prob - ans) \n",
    "    err_sqr = error*error\n",
    "    rmse = math.sqrt(err_sqr.sum()/lenProb)\n",
    "    return rmse  \n",
    "\n",
    "\n",
    "\n",
    "def accuracyFunction(ans, prob): \n",
    "    ans = np.array(ans)\n",
    "    prob = np.array(prob)\n",
    "    prob[prob >= 0.5] = 1\n",
    "    prob[prob < 0.5] = 0\n",
    "    acc = metrics.accuracy_score(ans, prob)\n",
    "    return acc\n",
    "\n",
    "def get_cohenKappa(y, pred):\n",
    "    y = np.array(y)\n",
    "    pred = np.array(pred)\n",
    "    pred[pred >= 0.5] = 1\n",
    "    pred[pred < 0.5] = 0\n",
    "    cohenKappa = metrics.cohen_kappa_score(y, pred, labels=None, weights=None, sample_weight=None)\n",
    "    return cohenKappa\n",
    "\n",
    "def auc_roc(y, pred): \n",
    "    y = np.array(y)\n",
    "    pred = np.array(pred)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr) \n",
    "    return auc\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_PCA(array):\n",
    "    minPCA = round(np.nanmin(array),3)\n",
    "    maxPCA = round(np.nanmax(array),3) \n",
    "    array2=[]\n",
    "    for i in range(len(array)):\n",
    "        array2.append((array[i] - minPCA) / (maxPCA-minPCA))\n",
    "        \n",
    "    return array2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First stage function: difficulty\n",
    "def arrayDifficulty(inputData, Competency, Diff, A_count, Q_count, kcsPuzzleDict ,gDict,gamma, beta): \n",
    "\n",
    "    alpha = 1\n",
    "    alpha_denominator = 0\n",
    "    correct = 0\n",
    "    \n",
    "    arrayDiff = dict()\n",
    "\n",
    "    response = np.zeros((len(inputData), 1))\n",
    "    \n",
    "    for count, (index, item) in enumerate(inputData.iterrows()):\n",
    "            \n",
    "        alpha_denominator = 0\n",
    "        uid = item[student_id] \n",
    "        qid = item[puzzle_name] \n",
    "        \n",
    "        ## NEW ##\n",
    "        if(qid not in arrayDiff.keys()): arrayDiff[qid] = dict()        \n",
    "        \n",
    "        diff = dict()\n",
    "        diff[qid]=[]\n",
    "        comp= dict()\n",
    "        comp[uid]=[]\n",
    "        \n",
    "        # The student's current competence by component is multiplied by each component of the question he or she is facing. \n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            comp[uid].append(Competency[uid][k] * kcsPuzzleDict[qid][k])\n",
    "            diff[qid].append(Diff[qid][k] * kcsPuzzleDict[qid][k])\n",
    "            \n",
    "        # Adding up the competencies per component to obtain the global competence    \n",
    "        compTotal = np.sum(comp[uid])\n",
    "        diffTotal = np.sum(diff[qid])\n",
    "        \n",
    "        \n",
    "        # With the global competition and the difficulty of the question, the probability of solving it is calculated\n",
    "        probability = (1)/(1 + math.exp( -1 * (compTotal - diffTotal)))\n",
    "        \n",
    "        q_answered_count = Q_count[qid] \n",
    "        \n",
    "        # The puzzle is completed or no\n",
    "        if item[completed] == 1:\n",
    "\n",
    "            response[count] = 1\n",
    "            correct = 1\n",
    "        else:\n",
    "            response[count] = 0\n",
    "            correct = 0\n",
    "        \n",
    "\n",
    "        #Alpha component is calculated (normalization factor)\n",
    "        alpha_numerator = probability - correct\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            c_lambda = Competency[uid][k]\n",
    "            probability_lambda = (1)/(1 + math.exp( -1 * (c_lambda - Diff[qid][k])))\n",
    "            alpha_denominator = alpha_denominator + (correct - probability_lambda)\n",
    "        alpha = abs(alpha_numerator / alpha_denominator)\n",
    "\n",
    "        \n",
    "        Q_count[qid] += 1\n",
    "        A_count[uid] += 1\n",
    "        \n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            \n",
    "            u_answered_count = A_count[uid]\n",
    "            prevDiff = Diff[qid][k]\n",
    "                        \n",
    "            # Competency probability is calculated\n",
    "            probability = (1)/(1 + math.exp( -1 * (Competency[uid][k] - prevDiff)))\n",
    "            \n",
    "            # Update the difficulty\n",
    "            changeDiff = ((gamma)/(1 + beta * q_answered_count)) *alpha* (probability - correct)\n",
    "            Diff[qid][k] = Diff[qid][k] + kcsPuzzleDict[qid][k] * changeDiff\n",
    "            # Add difficulty\n",
    "            if(k not in arrayDiff[qid].keys()): arrayDiff[qid][k] = []\n",
    "            arrayDiff[qid][k].append(Diff[qid][k])\n",
    "            \n",
    "            # Update the competency                    \n",
    "            changeComp = kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability) \n",
    "            Competency[uid][k] = Competency[uid][k]+changeComp\n",
    "                            \n",
    "                \n",
    "    return arrayDiff\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ELO algorithm with static difficulty\n",
    "def multiTopic_ELO(inputData, Competency, Diff, A_count, Q_count, kcsPuzzleDict ,gDict,gamma, beta): \n",
    "\n",
    "    alpha = 1\n",
    "    alpha_denominator = 0\n",
    "    correct = 0\n",
    "    prob_test = dict()\n",
    "    ans_test = dict()  \n",
    "    probUser = dict()\n",
    "    competencyPartial = dict()\n",
    "    userPuzzles = dict()\n",
    "    completedPartialData = dict()\n",
    "    \n",
    "    failAtt = dict()\n",
    "    \n",
    "    probUserTest = dict()\n",
    "    ansUserTest = dict()\n",
    "    \n",
    "    contPuzzlesUser = dict()\n",
    "\n",
    "    response = np.zeros((len(inputData), 1))\n",
    "    \n",
    "    for count, (index, item) in enumerate(inputData.iterrows()):\n",
    "            \n",
    "        alpha_denominator = 0\n",
    "        uid = item[student_id] \n",
    "        qid = item[puzzle_name] \n",
    "        time = item[timestamp]\n",
    "        \n",
    "        if(uid not in failAtt.keys()):\n",
    "            failAtt[uid]= dict()\n",
    "        if(qid not in failAtt[uid].keys()):\n",
    "            failAtt[uid][qid] = 0\n",
    "        \n",
    "        if(uid not in userPuzzles.keys()): userPuzzles[uid] = []\n",
    "        userPuzzles[uid].append(qid)\n",
    "        \n",
    "        # Cont the puzzles per user (intermediate and advanced)\n",
    "        if(uid not in contPuzzlesUser.keys()):\n",
    "            contPuzzlesUser[uid] = set()\n",
    "        if(qid in intermediatePuzzles or qid in advancedPuzzles):    \n",
    "            contPuzzlesUser[uid].add(qid)    \n",
    "        \n",
    "        diff = dict()\n",
    "        diff[qid]=[]\n",
    "        comp= dict()\n",
    "        comp[uid]=[]\n",
    "        \n",
    "        # The student's current competence by component is multiplied by each component of the question he or she is facing. \n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            comp[uid].append(Competency[uid][k] * kcsPuzzleDict[qid][k])\n",
    "            diff[qid].append(Diff[qid][k] * kcsPuzzleDict[qid][k])\n",
    "            \n",
    "        # Adding up the competencies per component to obtain the global competence    \n",
    "        compTotal = np.sum(comp[uid])\n",
    "        diffTotal = np.sum(diff[qid])\n",
    "        \n",
    "        # With the global competition and the difficulty of the question, the probability of solving it is calculated\n",
    "        probability = (1)/(1 + math.exp( -1 * (compTotal - diffTotal)))\n",
    "        \n",
    "        if(uid not in prob_test.keys()):\n",
    "            prob_test[uid] = dict()\n",
    "            \n",
    "        if(uid not in probUserTest.keys()):\n",
    "            probUserTest[uid] = []\n",
    "            \n",
    "        if(uid not in ansUserTest.keys()):\n",
    "            ansUserTest[uid] = []    \n",
    "        \n",
    "        # Save the probabilities\n",
    "        prob_test[uid][qid]=probability\n",
    "        q_answered_count = Q_count[qid] \n",
    "        \n",
    "        if(qid in intermediatePuzzles or qid in advancedPuzzles):\n",
    "            probUserTest[uid].append(probability)\n",
    "        \n",
    "        # The puzzle is completed or no\n",
    "        if item[completed] == 1:\n",
    "\n",
    "            response[count] = 1\n",
    "            correct = 1\n",
    "        else:\n",
    "            response[count] = 0\n",
    "            correct = 0\n",
    "            failAtt[uid][qid] +=1\n",
    "        \n",
    "        if(uid not in ans_test.keys()):\n",
    "            ans_test[uid] = dict()\n",
    "            \n",
    "        # Save the real result    \n",
    "        ans_test[uid][qid] = correct\n",
    "        if(qid in intermediatePuzzles or qid in advancedPuzzles):\n",
    "            ansUserTest[uid].append(correct)\n",
    "\n",
    "        #Alpha component is calculated (normalization factor)\n",
    "        alpha_numerator = probability - correct\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            c_lambda = Competency[uid][k]\n",
    "            probability_lambda = (1)/(1 + math.exp( -1 * (c_lambda - Diff[qid][k])))\n",
    "            alpha_denominator = alpha_denominator + (correct - probability_lambda)\n",
    "        alpha = abs(alpha_numerator / alpha_denominator)\n",
    "\n",
    "        # Initialize new data\n",
    "        if(uid not in probUser.keys()):\n",
    "            probUser[uid] = dict()\n",
    "            competencyPartial[uid] = dict()\n",
    "        \n",
    "        probUser[uid][qid]= probability\n",
    "        \n",
    "        Q_count[qid] += 1\n",
    "        A_count[uid] += 1\n",
    "        for k in kcsPuzzleDict[qid]:\n",
    "            \n",
    "            u_answered_count = A_count[uid]\n",
    "            c = Competency[uid][k] \n",
    "            prevDiff = Diff[qid][k]\n",
    "            \n",
    "            key = uid+'~'+qid+'~'+k+'~'+str(round(Competency[uid][k],3)) + '~'+str(round(prevDiff,3))\n",
    "            \n",
    "            # Competency probability is calculated\n",
    "            probability = (1)/(1 + math.exp( -1 * (Competency[uid][k] - prevDiff)))\n",
    "            \n",
    "            # Update the difficulty\n",
    "            #changeDiff = ((gamma)/(1 + beta * q_answered_count)) *alpha* (probability - correct)\n",
    "            #Diff[qid][k] = Diff[qid][k] + kcsPuzzleDict[qid][k] * changeDiff\n",
    "            \n",
    "            # Update the competency\n",
    "            # if puzzle is in tutorial puzzles, we do not update the competency\n",
    "            weightAtt = 0\n",
    "            if(qid not in tutorialPuzzles and correct ==1):\n",
    "                # Fail limit\n",
    "                if(failAtt[uid][qid] >= 5): failAtt[uid][qid] == 5\n",
    "                    \n",
    "                weightAtt = (1-(failAtt[uid][qid]/10))\n",
    "                complete_change = kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability)\n",
    "                changeComp = kcsPuzzleDict[qid][k] * (gamma)/(1 + beta * u_answered_count) * alpha * (correct - probability) * weightAtt \n",
    "                Competency[uid][k] = Competency[uid][k]+changeComp\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                changeComp = 0\n",
    "                complete_change = 0\n",
    "                \n",
    "            # Save the new data\n",
    "            completedPartialData[key] = {'prob': 0, 'kcs importance': 0, 'correct': -1, 'Difficulty': 0, 'Group Difficulty': 0, 'update competency': 0}\n",
    "            completedPartialData[key]['prob'] = probability\n",
    "            completedPartialData[key]['kcs importance'] = kcsPuzzleDict[qid][k]\n",
    "            completedPartialData[key]['correct'] = correct\n",
    "            completedPartialData[key]['Difficulty'] = round(Diff[qid][k],3)\n",
    "            completedPartialData[key]['Weight'] = weightAtt\n",
    "            completedPartialData[key]['cont_puzzles'] = len(contPuzzlesUser[uid])\n",
    "            completedPartialData[key]['timestamp'] = time\n",
    "            completedPartialData[key]['changeComp'] = changeComp\n",
    "            completedPartialData[key]['complete_change_comp'] = complete_change\n",
    "            #completedPartialData[key]['changeDiff'] = kcsPuzzleDict[qid][k] * changeDiff\n",
    "            \n",
    "            if(k not in competencyPartial[uid].keys()): competencyPartial[uid][k] = []\n",
    "            competencyPartial[uid][k].append(Competency[uid][k])\n",
    "            \n",
    "                \n",
    "    return Competency, A_count , Q_count, prob_test, ans_test, competencyPartial, probUser, userPuzzles, completedPartialData, probUserTest, ansUserTest, contPuzzlesUser\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(gamma, beta, output, totalData, train_set, test_set,basado):\n",
    "    \n",
    "    \n",
    "    uDict,gDict,qDict,kcDict,kcsPuzzleDict = loadDataset(totalData)\n",
    "    competency_ELO = pd.DataFrame()\n",
    "    competency_ELO_PCA = pd.DataFrame()\n",
    "    difficulty_ELO = pd.DataFrame()    \n",
    "\n",
    "\n",
    "\n",
    "    # First stage\n",
    "    question_difficulty_array = dict() \n",
    "    question_counter_array = dict() \n",
    "\n",
    "\n",
    "    for q in qDict.keys():\n",
    "        if(q not in question_difficulty_array.keys()):\n",
    "            question_difficulty_array[q]=dict()\n",
    "            question_counter_array[q]=dict()\n",
    "            question_counter_array[q]=0\n",
    "\n",
    "        for k in kcDict.keys():\n",
    "            question_difficulty_array[q][k]=0   \n",
    "\n",
    "\n",
    "    learner_competency_array = dict() \n",
    "    response_counter_array = dict() \n",
    "    for user in uDict.keys():\n",
    "        if(user not in learner_competency_array.keys()):\n",
    "            learner_competency_array[user]=dict()\n",
    "            response_counter_array[user]=dict()\n",
    "            response_counter_array[user]=0\n",
    "        for k in kcDict.keys():\n",
    "            learner_competency_array[user][k]=0\n",
    "\n",
    "\n",
    "    # Second Stage\n",
    "    puzzleDiffMean = basado.copy()\n",
    "\n",
    "    if(output == 'metrics'):\n",
    "        \n",
    "        question_counter_Model = dict() \n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_counter_Model.keys()):\n",
    "                question_counter_Model[q]=dict()\n",
    "                question_counter_Model[q]=0\n",
    " \n",
    "\n",
    "\n",
    "        learner_competency_Model = dict() \n",
    "        response_counter_Model = dict()\n",
    "        for user in uDict.keys():\n",
    "            if(user not in learner_competency_Model.keys()):\n",
    "                learner_competency_Model[user]=dict()\n",
    "                response_counter_Model[user]=dict()\n",
    "                response_counter_Model[user]=0\n",
    "            for k in kcDict.keys():\n",
    "                learner_competency_Model[user][k]=0\n",
    "\n",
    "        learner_competency_train, response_counter_train, question_counter_train, prob_train, ans_train, competencyPartial_train, probUser_train, userPuzzles_train, completedPartialData, probUserTrain, ansUserTrain, contPuzzlesUser_Train = multiTopic_ELO(train_set, learner_competency_Model, puzzleDiffMean, response_counter_Model, question_counter_Model, kcsPuzzleDict,gDict,gamma, beta)\n",
    "        learner_competency_test ,response_counter_test, question_counter_test, prob_test, ans_test,competencyPartial_test, probUser_test, userPuzzles_test, completedPartialData, probUserT, ansUserT, contPuzzlesUser_Test = multiTopic_ELO(test_set, learner_competency_train, puzzleDiffMean, response_counter_train, question_counter_train, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "\n",
    "\n",
    "        # Quality metrics\n",
    "        group_prob_test = []\n",
    "        contUser =0\n",
    "        contT = 0\n",
    "        for user in prob_test.keys():\n",
    "            contUser+=1\n",
    "            for task in prob_test[user].keys():\n",
    "                contT+=1\n",
    "                group_prob_test.append(prob_test[user][task])\n",
    "\n",
    "        group_ans_test = []\n",
    "        for user in ans_test.keys():\n",
    "            for task in ans_test[user].keys():\n",
    "                group_ans_test.append(ans_test[user][task])        \n",
    "\n",
    "\n",
    "        accuracy = accuracyFunction(group_ans_test, group_prob_test)    \n",
    "        auc = auc_roc(group_ans_test, group_prob_test)\n",
    "        kappa = get_cohenKappa(group_ans_test, group_prob_test)\n",
    "\n",
    "        return accuracy, auc, kappa\n",
    "        \n",
    "        \n",
    "        \n",
    "    else: \n",
    "\n",
    "\n",
    "        # Data for step by step data output\n",
    "        question_counter = dict() \n",
    "\n",
    "        for q in qDict.keys():\n",
    "            if(q not in question_counter.keys()):\n",
    "                question_counter[q]=dict()\n",
    "                question_counter[q]=0\n",
    "\n",
    "        learner_competency = dict() \n",
    "        response_counter = dict() \n",
    "        for user in uDict.keys():\n",
    "            if(user not in learner_competency.keys()):\n",
    "                learner_competency[user]=dict()\n",
    "                response_counter[user]=dict()\n",
    "                response_counter[user]=0\n",
    "            for k in kcDict.keys():\n",
    "                learner_competency[user][k]=0\n",
    "\n",
    "        # Multi-ELO function        \n",
    "        learner_competency_total, response_counter_total, question_counter_total, prob_total, ans_total, competencyPartial_total, probUser_total, userPuzzles_total, completedPartialData, probUserTest, ansUserTest, contPuzzlesUser = multiTopic_ELO(totalData, learner_competency, puzzleDiffMean, response_counter, question_counter, kcsPuzzleDict,gDict,gamma, beta)\n",
    "\n",
    "\n",
    "        totalCompetencyGMD = []\n",
    "        totalCompetencyCO5 = []\n",
    "        totalCompetencyCO6 = []\n",
    "        totalCompetencyMG1 = []\n",
    "\n",
    "\n",
    "        for user in learner_competency.keys():\n",
    "            for x in learner_competency[user]:\n",
    "                if(x == 'GMD.4'):\n",
    "                    print('entro GMD4')\n",
    "                    totalCompetencyGMD.append(learner_competency[user][x])\n",
    "                elif(x == 'CO.5'):\n",
    "                    print('entro CO5')\n",
    "                    totalCompetencyCO5.append(learner_competency[user][x]) \n",
    "                elif(x == 'CO.6'):\n",
    "                    print('entro CO6')\n",
    "                    totalCompetencyCO6.append(learner_competency[user][x])\n",
    "                elif(x == 'MG.1'):\n",
    "                    print('entro MG1')\n",
    "                    totalCompetencyMG1.append(learner_competency[user][x])    \n",
    "\n",
    "\n",
    "        minCompetencyGMD = min(totalCompetencyGMD)   \n",
    "        maxCompetencyGMD = max(totalCompetencyGMD)\n",
    "\n",
    "        print('La minimas competencias GMD son: ', minCompetencyGMD)\n",
    "        print('La maximas competencias GMD son: ', maxCompetencyGMD)\n",
    "\n",
    "        minCompetencyCO5 = min(totalCompetencyCO5)   \n",
    "        maxCompetencyCO5 = max(totalCompetencyCO5)\n",
    "\n",
    "        minCompetencyCO6 = min(totalCompetencyCO6)   \n",
    "        maxCompetencyCO6 = max(totalCompetencyCO6)\n",
    "\n",
    "        minCompetencyMG1 = min(totalCompetencyMG1)   \n",
    "        maxCompetencyMG1 = max(totalCompetencyMG1)\n",
    "\n",
    "        normalized_learner_competency = dict()\n",
    "        normalized_global_competency = dict()\n",
    "        for user in learner_competency.keys():\n",
    "            normalized_learner_competency[user]=dict()\n",
    "            normalized_global_competency[user] = 0\n",
    "            for x in learner_competency[user]:\n",
    "                if(x == 'GMD.4'):\n",
    "                    normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyGMD)/(maxCompetencyGMD-minCompetencyGMD)\n",
    "                    normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "\n",
    "                elif(x == 'CO.5'):\n",
    "                    normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyCO5)/(maxCompetencyCO5-minCompetencyCO5)\n",
    "                    normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "\n",
    "                elif(x == 'CO.6'):\n",
    "                    normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyCO6)/(maxCompetencyCO6-minCompetencyCO6)\n",
    "                    normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "\n",
    "                elif(x == 'MG.1'):\n",
    "                    normalized_learner_competency[user][x]= (learner_competency[user][x]- minCompetencyMG1)/(maxCompetencyMG1-minCompetencyMG1)\n",
    "                    normalized_global_competency[user] += normalized_learner_competency[user][x]\n",
    "\n",
    "\n",
    "        for user in normalized_global_competency.keys():\n",
    "            normalized_global_competency[user] = normalized_global_competency[user]/len(kcs)\n",
    "\n",
    "\n",
    "        # Normalization Difficulty    \n",
    "        totalDiffGMD = []\n",
    "        totalDiffCO5 = []\n",
    "        totalDiffCO6 = []\n",
    "        totalDiffMG1 = []\n",
    "\n",
    "        for puzzle in puzzleDiffMean.keys():\n",
    "            for x in puzzleDiffMean[puzzle]:\n",
    "                if(x == 'GMD.4'):\n",
    "                    totalDiffGMD.append(puzzleDiffMean[puzzle][x])\n",
    "                elif(x == 'CO.5'):\n",
    "                    totalDiffCO5.append(puzzleDiffMean[puzzle][x]) \n",
    "                elif(x == 'CO.6'):\n",
    "                    totalDiffCO6.append(puzzleDiffMean[puzzle][x])\n",
    "                elif(x == 'MG.1'):\n",
    "                    totalDiffMG1.append(puzzleDiffMean[puzzle][x])    \n",
    "\n",
    "\n",
    "        minDiffGMD = min(totalDiffGMD)   \n",
    "        maxDiffGMD = max(totalDiffGMD)\n",
    "\n",
    "        minDiffCO5 = min(totalDiffCO5)   \n",
    "        maxDiffCO5 = max(totalDiffCO5)\n",
    "\n",
    "        minDiffCO6 = min(totalDiffCO6)   \n",
    "        maxDiffCO6 = max(totalDiffCO6)\n",
    "\n",
    "        minDiffMG1 = min(totalDiffMG1)   \n",
    "        maxDiffMG1 = max(totalDiffMG1)\n",
    "\n",
    "        normalized_question_difficulty = dict()\n",
    "\n",
    "        for puzzle in puzzleDiffMean.keys():\n",
    "            normalized_question_difficulty[puzzle]=dict()\n",
    "            for x in puzzleDiffMean[puzzle]:\n",
    "                if(x == 'GMD.4'):\n",
    "                    normalized_question_difficulty[puzzle][x]= (puzzleDiffMean[puzzle][x]- minDiffGMD)/(maxDiffGMD-minDiffGMD)\n",
    "\n",
    "                elif(x == 'CO.5'):\n",
    "                    normalized_question_difficulty[puzzle][x]= (puzzleDiffMean[puzzle][x]- minDiffCO5)/(maxDiffCO5-minDiffCO5)\n",
    "\n",
    "                elif(x == 'CO.6'):\n",
    "                    normalized_question_difficulty[puzzle][x]= (puzzleDiffMean[puzzle][x]- minDiffCO6)/(maxDiffCO6-minDiffCO6)\n",
    "\n",
    "                elif(x == 'MG.1'):\n",
    "                    normalized_question_difficulty[puzzle][x]= (puzzleDiffMean[puzzle][x]- minDiffMG1)/(maxDiffMG1-minDiffMG1)\n",
    "\n",
    "        if(output == 'step by step'):\n",
    "\n",
    "            for i in completedPartialData.keys():\n",
    "                    key_split = i.split('~')\n",
    "                    competency_ELO.at[i, 'group'] = gDict[key_split[0]]    \n",
    "                    competency_ELO.at[i, 'user'] = key_split[0] \n",
    "                    competency_ELO.at[i, 'task_id'] = key_split[1]\n",
    "                    competency_ELO.at[i, 'kc'] = key_split[2]\n",
    "                    competency_ELO.at[i, 'final_kc_competency'] = round(normalized_learner_competency[key_split[0]][key_split[2]],3)\n",
    "                    competency_ELO.at[i, 'final_global_competency'] = round(normalized_global_competency[key_split[0]],3)\n",
    "                    competency_ELO.at[i, 'current_competency'] = key_split[3]\n",
    "                    competency_ELO.at[i, 'probability'] = round(completedPartialData[i]['prob'],3)\n",
    "                    competency_ELO.at[i, 'correct'] = completedPartialData[i]['correct']\n",
    "                    competency_ELO.at[i, 'kcs_importance'] = round(completedPartialData[i]['kcs importance'],3)\n",
    "                    competency_ELO.at[i, 'difficulty'] = round(puzzleDiffMean[key_split[1]][key_split[2]],3)\n",
    "                    competency_ELO.at[i, 'weight_att'] = round(completedPartialData[i]['Weight'],3)\n",
    "                    competency_ELO.at[i, 'timestamp'] = completedPartialData[i]['timestamp']\n",
    "                    if(len(ansUserTest[key_split[0]]) > 0): competency_ELO.at[i, 'accuracy'] = str(round(accuracyFunction(ansUserTest[key_split[0]], probUserTest[key_split[0]]), 3)) \n",
    "                    else: competency_ELO.at[i, 'accuracy'] = str(np.nan)                    \n",
    "                    competency_ELO.at[i, 'n_puzzles_attempted'] = len(contPuzzlesUser[key_split[0]])\n",
    "                    competency_ELO.at[i, 'p_attempted'] = round((len(contPuzzlesUser[key_split[0]]) * 100)/((len(intermediatePuzzles) + len(advancedPuzzles))-1), 3)\n",
    "                    competency_ELO.at[i, 'change_competency'] = round(completedPartialData[i]['changeComp'],3)\n",
    "                    competency_ELO.at[i, 'complete_change_comp'] = round(completedPartialData[i]['complete_change_comp'],3)\n",
    "                    #competency_ELO.at[i, 'change_difficulty'] = round(completedPartialData[i]['changeDiff'],3)\n",
    "\n",
    "            #data output preparation  \n",
    "            competency_ELO = pd.DataFrame(competency_ELO, columns = ['group','user','task_id', 'timestamp','kc','kcs_importance','final_kc_competency', 'final_global_competency','current_competency','change_competency','weight_att','complete_change_comp', 'probability', 'correct','accuracy','n_puzzles_attempted','p_attempted', 'difficulty'])\n",
    "\n",
    "            return competency_ELO\n",
    "\n",
    "        \n",
    "        if(output == 'standard'): \n",
    "            \n",
    "            # Data for final data output (difficulty)\n",
    "            concatedTaskKc = dict()\n",
    "\n",
    "            for q in qDict.keys():\n",
    "                for k in kcsPuzzleDict[q].keys():\n",
    "                    concatedTaskKc[q+'~'+k] = 0\n",
    "                    \n",
    "\n",
    "            for i in concatedTaskKc.keys():\n",
    "                key_split = i.split('~')\n",
    "                difficulty_ELO.at[i, 'task_id'] = key_split[0]\n",
    "                difficulty_ELO.at[i, 'kc'] = key_split[1]\n",
    "                difficulty_ELO.at[i, 'difficulty'] = round(puzzleDiffMean[key_split[0]][key_split[1]],3)  \n",
    "                difficulty_ELO.at[i, 'normalized_difficulty'] = round(normalized_question_difficulty[key_split[0]][key_split[1]],3)               \n",
    "\n",
    "\n",
    "\n",
    "            idComplet = dict()\n",
    "            for g in gDict.values():\n",
    "                for u in gDict.keys():\n",
    "                    for k in kcs:\n",
    "                        iCom = g+'~'+u+'~'+k\n",
    "                        idComplet[iCom] = 0\n",
    "\n",
    "            for i in idComplet.keys():\n",
    "                key_split = i.split('~')\n",
    "                competency_ELO.at[i, 'group'] = key_split[0]    \n",
    "                competency_ELO.at[i, 'user'] = key_split[1]    \n",
    "                competency_ELO.at[i, 'kc'] = key_split[2]\n",
    "                competency_ELO.at[i, 'competency'] = round(normalized_learner_competency[key_split[1]][key_split[2]],3) \n",
    "                if(len(ansUserTest[key_split[1]]) > 0): competency_ELO_PCA.at[i, 'accuracy'] = str(round(accuracyFunction(ansUserTest[key_split[1]], probUserTest[key_split[1]]), 3)) \n",
    "                else: competency_ELO_PCA.at[i, 'accuracy'] = np.nan\n",
    "                if(len(ansUserTest[key_split[1]]) > 0): competency_ELO.at[i, 'accuracy'] = str(round(accuracyFunction(ansUserTest[key_split[1]], probUserTest[key_split[1]]), 3)) \n",
    "                else: competency_ELO.at[i, 'accuracy'] = str(np.nan)\n",
    "                competency_ELO.at[i, 'n_puzzles_attempted'] = len(contPuzzlesUser[key_split[1]])\n",
    "                competency_ELO_PCA.at[i, 'n_puzzles_attempted'] = len(contPuzzlesUser[key_split[1]])\n",
    "                competency_ELO.at[i, 'p_attempted'] = round((len(contPuzzlesUser[key_split[1]]) * 100)/((len(intermediatePuzzles) + len(advancedPuzzles))-1), 3)\n",
    "            \n",
    "            # Replace NaN values by 0\n",
    "            competency_ELO_PCA['accuracy'] = competency_ELO_PCA['accuracy'].replace(np.nan, 0)\n",
    "            # Data preprocesing to match variable weights\n",
    "            scaler = StandardScaler()\n",
    "            scaler.fit(competency_ELO_PCA)\n",
    "            scaled_data = scaler.transform(competency_ELO_PCA)\n",
    "            \n",
    "            # PCA object and look for the main variables\n",
    "            pca = PCA(n_components=1)\n",
    "            pca.fit(scaled_data)\n",
    "            # Dimensionality reduction\n",
    "            x_pca = pca.transform(scaled_data)\n",
    "            \n",
    "            # Re-enter the NaN values\n",
    "            x_pca = np.round(np.where(x_pca == min(x_pca), np.nan, x_pca),3)\n",
    "            \n",
    "            # Normalized\n",
    "            x_pca_normalized = np.round(normalized_PCA(x_pca),3)\n",
    "            \n",
    "            #data output preparation  \n",
    "            difficulty_ELO = pd.DataFrame(difficulty_ELO, columns = ['task_id','kc', 'difficulty','normalized_difficulty'])\n",
    "            competency_ELO = pd.DataFrame(competency_ELO, columns = ['group','user','kc', 'competency', 'accuracy','n_puzzles_attempted','p_attempted'])\n",
    "            \n",
    "\n",
    "            competency_ELO['pca'] = x_pca.astype(str)\n",
    "            competency_ELO['pca_normalized'] = x_pca_normalized.astype(str)\n",
    "            \n",
    "            \n",
    "            return competency_ELO, difficulty_ELO\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                             time               type  \\\n",
      "163298  597708 2019-10-23 13:44:49.604763-04:00  ws-check_solution   \n",
      "215214  585610 2019-10-23 13:09:59.140974-04:00     ws-create_user   \n",
      "215242  585636 2019-10-23 13:10:05.094066-04:00     ws-start_level   \n",
      "215247  585641 2019-10-23 13:10:06.196056-04:00  ws-puzzle_started   \n",
      "215252  585646 2019-10-23 13:10:08.428204-04:00   ws-click_nothing   \n",
      "...        ...                              ...                ...   \n",
      "324776  696863 2019-10-25 09:56:21.694074-04:00      ws-move_shape   \n",
      "324780  696867 2019-10-25 09:56:22.330220-04:00    ws-select_shape   \n",
      "324786  696874 2019-10-25 09:56:23.463786-04:00      ws-move_shape   \n",
      "324799  696887 2019-10-25 09:56:26.586716-04:00        ws-snapshot   \n",
      "324809  696897 2019-10-25 09:56:28.196671-04:00    ws-exit_to_menu   \n",
      "\n",
      "                                                     data  \\\n",
      "163298  {\"timeStamp\": 760.3634033203125, \"screenPos\": ...   \n",
      "215214  {\"group\": \"e6af7d42084352a39449e6d0a09b18cd\", ...   \n",
      "215242  {\"user\": \"0d35fa2868a21199e36b159b49ae6aad\", \"...   \n",
      "215247  {\"timeStamp\": 0.0, \"screenPos\": {\"x\": 0.265625...   \n",
      "215252  {\"timeStamp\": 2.3995699882507324, \"screenPos\":...   \n",
      "...                                                   ...   \n",
      "324776  {\"timeStamp\": 107.70359802246094, \"screenPos\":...   \n",
      "324780  {\"timeStamp\": 108.40550231933594, \"screenPos\":...   \n",
      "324786  {\"timeStamp\": 109.5303726196289, \"screenPos\": ...   \n",
      "324799  {\"timeStamp\": 112.55677795410156, \"screenPos\":...   \n",
      "324809  {\"timeStamp\": 114.24169158935547, \"screenPos\":...   \n",
      "\n",
      "                              session_id  \n",
      "163298  l0iun73jzec6z56rayg9xesk63pvlw9d  \n",
      "215214  l0iun73jzec6z56rayg9xesk63pvlw9d  \n",
      "215242  l0iun73jzec6z56rayg9xesk63pvlw9d  \n",
      "215247  l0iun73jzec6z56rayg9xesk63pvlw9d  \n",
      "215252  l0iun73jzec6z56rayg9xesk63pvlw9d  \n",
      "...                                  ...  \n",
      "324776  dgs66k6f097o6u2h298iobf17dv7kw2y  \n",
      "324780  dgs66k6f097o6u2h298iobf17dv7kw2y  \n",
      "324786  dgs66k6f097o6u2h298iobf17dv7kw2y  \n",
      "324799  dgs66k6f097o6u2h298iobf17dv7kw2y  \n",
      "324809  dgs66k6f097o6u2h298iobf17dv7kw2y  \n",
      "\n",
      "[2588 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "dataEvents['user'] = [json.loads(x)['user'] if 'user' in json.loads(x).keys() else '' for x in dataEvents['data']]\n",
    "dataEventsUser = dataEvents[dataEvents['user']=='0d35fa2868a21199e36b159b49ae6aad']\n",
    "dataEventsUser = dataEventsUser.drop(columns=['user'])\n",
    "\n",
    "totalData, train_set, test_set = adaptedData(dataEventsUser)\n",
    "\n",
    "print(dataEventsUser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entro GMD4\n",
      "entro CO5\n",
      "entro CO6\n",
      "entro MG1\n",
      "La minimas competencias GMD son:  0.5988952618007226\n",
      "La maximas competencias GMD son:  0.5988952618007226\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mZeroDivisionError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1084\\1578520726.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mcompetency_ELO\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdifficulty_ELO\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mrun\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1.8\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0.05\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'standard'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtotalData\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtrain_set\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_set\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mdifficulty_puzzles_dict\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_1084\\440187557.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(gamma, beta, output, totalData, train_set, test_set, basado)\u001B[0m\n\u001B[0;32m    155\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mlearner_competency\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    156\u001B[0m                 \u001B[1;32mif\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'GMD.4'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 157\u001B[1;33m                     \u001B[0mnormalized_learner_competency\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mlearner_competency\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m-\u001B[0m \u001B[0mminCompetencyGMD\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m/\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmaxCompetencyGMD\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mminCompetencyGMD\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    158\u001B[0m                     \u001B[0mnormalized_global_competency\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mnormalized_learner_competency\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0muser\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mZeroDivisionError\u001B[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "competency_ELO, difficulty_ELO= run(1.8, 0.05, 'standard', totalData, train_set, test_set,difficulty_puzzles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competency_ELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "competency_ELO.to_csv(\"elo-Output2.csv\", decimal = \".\", sep =\";\", mode='w')\n",
    "difficulty_ELO.to_csv(\"elo-puzzle-Output2.csv\", decimal = \".\", sep =\";\", mode='w')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#cb71040b5bd1341a34afc24961536ebd\n",
    "#c6262795f034865c9e9203305638ee79\n",
    "#7a01ab37bd2729626dcaf96166390315\n",
    "#95cd1f045a0329cf5595ae734ae7ae43\n",
    "#4fe25833f555e9903d2bb6bbeec3fbfb\n",
    "#e6af7d42084352a39449e6d0a09b18cd\n",
    "#8cbfa61cb2b025b16b04a8e470422960\n",
    "#e21640b4aea9349ad77d86d6017cb061"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
